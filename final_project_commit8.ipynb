{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project guidelines\n",
    "\n",
    "**Note:** Use these guidelines if and only if you are pursuing a **final project of your own design**. For those taking the final exam instead of the project, see the (separate) [final exam notebook](https://github.com/wilkens-teaching/info3350-f20/blob/master/final_exam/final_exam.ipynb).\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "These guidelines are intended for **undergraduates enrolled in INFO 3350**. If you are a graduate student enrolled in INFO 6350, you're welcome to consult the informartion below, but you have wider latitude to design and develop your project in line with your research goals.\n",
    "\n",
    "### The task\n",
    "\n",
    "Your task is to: identify an interesting problem connected to the humanities or humanistic social sciences that's addressable with the help of computational methods, formulate a hypothesis about it, devise an experiment or experiments to test your hypothesis, present the results of your investigations, and discuss your findings.\n",
    "\n",
    "These tasks essentially replicate the process of writing an academic paper. You can think of your project as a paper in miniature.\n",
    "\n",
    "You are free to present each of these tasks as you see fit. You should use narrative text (that is, your own writing in a markdown cell), citations of others' work, numerical results, tables of data, and static and/or interactive visualizations as appropriate. Total length is flexible and depends on the number of people involved in the work, as well as the specific balance you strike between the ambition of your question and the sophistication of your methods. But be aware that numbers never, ever speak for themselves. Quantitative results presented without substantial discussion are unlikely to earn high marks. \n",
    "\n",
    "Your project should reflect, at minimum, ten or more hours of work by each participant, though you will be graded on the quality of your work, not the amount of time it took you to produce it.\n",
    "\n",
    "### Format\n",
    "\n",
    "You should submit your project as a Jupyter notebook, along with all data necessary to reproduce your analysis. If your dataset is too large to share easily, let us know in advance so that we can find a workaround. If you have a reason to prefer a presentation format other than a notebook, likewise let us know so that we can discuss the options.\n",
    "\n",
    "Your report should have four basic sections (provided in cells below for ease of reference):\n",
    "\n",
    "1. **Introduction and hypothesis.** What problem are you working on? Why is it interesting and important? What have other people said about it? What do you expect to find?\n",
    "2. **Corpus, data, and methods.** What data have you used? Where did it come from? How did you collect it? What major methods will you use to analyze it? Why are those methods the appropriate ones?\n",
    "3. **Results.** What did you find? How did you find it? How should we read your figures?\n",
    "4. **Discussion and conclusions.** What does it all mean? Do your results support your hypothesis? Why or why not? What are the limitations of your study and how might those limitations be addressed in future work?\n",
    "\n",
    "Within each of those sections, you may use as many code and markdown cells as you like. You may, of course, address additional questions or issues not listed above.\n",
    "\n",
    "All code used in the project should be present in the notebook (except for widely-available libraries that you import), but **be sure that we can read and understand your report in full without rerunning the code**. Be sure, too, to explain what you're doing along the way, both by describing your data and methods and by writing clean, well commented code.\n",
    "\n",
    "### Grading\n",
    "\n",
    "This project takes the place of the take-home final exam for the course. It is worth 20% of your overall grade. You will be graded on the quality and ambition of each aspect of the project. No single component is more important than the others.\n",
    "\n",
    "### Practical details\n",
    "\n",
    "* The project is due at **5:00pm EST on Saturday, December 19, 2020** via upload to CMS.\n",
    "* You may work alone or in a group of up to three total members.\n",
    "    * If you work in a group, be sure to list the names of the group members.\n",
    "    * For groups, submit one notebook for the entire group. **Each group member should also submit an individual statement of responsibility** that describes in general terms who performed which parts of the project.\n",
    "* You may post questions on Campuswire, but should do so privately (visible to course staff only).\n",
    "* Interactive visualizations do not always work when embedded in shared notebooks. If you plan to use interactives, you may need to host them elsewhere and link to them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info Wars: Building a Fake News Classifier based on 2016 Presidential Election Related Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPR reported that in the months leading up to the 2016 presidential election, the top 20 fake news stories beat out the top 20 hard news in terms of engagement (shares, reactions and comments) on Facebook (Kurtzleben, 2018). These findings from Buzzfeed Analysis underscores the extent to which disinformation has penetrated American media ecosystem, and is further amplified by social media's ease in sharing false content outside of personal networks. Since then, there have been many calls for meaningful content regulation of fake news on social media. At the heart of this problem is finding a way to distinguish real news from false ones. We hope to build off of the existing work done by many computer scientists and machine learning researchers to utilize the methods and tools we've learned in this course to build a model that classifies real and fake news stories. \n",
    "We were also inspired by another study from Cornell University researchers, which analyzed English-language articles about the pandemic and found that President Trump was the largest driver of coronavirus misinformation (Stolberg and Weiland, 2020). Thus, we aimed to also apply a similar scope to our project and analyze one set of related articles in a specific timeframe, and all of which are considered \"hard news\". This is defined to be serious news concerning foreign affairs, politics or recent events considered to be of national or international significance (Britannica). \n",
    "In addition, we also analyzed multiple academic papers to familiarize ourselves on existing methodologies and approaches to building a fake news classifier. We evaluated methods both in data pre-processing and also model selection. Our goal was to train a classifier based on 2016 hard news, and evaluate accuracy of the model. \n",
    "Methods we used to iterate and optimize our classifier (and expanded on below) include: lemmatization, tokenization, vectorization, selectkbest, and SVC, MLP, decision tree and random forest. \n",
    "We hypothesize that Trump will likely be a highly relevant feature in our classifier, and we are interested in exploring the other relevant word-based features to include in our final model. We also anticipate that the decision tree classifier, as a consequence of its tendency towards overfitting, will produce our highest accuracy score in terms of classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing and corpus building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = 'fake_or_real_news.csv'\n",
    "text_df = pd.read_csv('fake_or_real_news.csv')\n",
    "text_df.head()\n",
    "\n",
    "#text_df.iloc[0].text\n",
    "# text_df.iloc[6330].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to filter out empty stories (keep only len texts > 0\n",
    "# text_df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "# mask = list(text_df['text'].apply(lambda x: len(x) > 0))\n",
    "# df = text_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       FAKE\n",
       "1       FAKE\n",
       "2       REAL\n",
       "3       FAKE\n",
       "4       REAL\n",
       "        ... \n",
       "6330    REAL\n",
       "6331    FAKE\n",
       "6332    FAKE\n",
       "6333    REAL\n",
       "6334    REAL\n",
       "Name: label, Length: 6335, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_col = text_df['text']\n",
    "y_labels = text_df['label']\n",
    "\n",
    "display(y_labels)\n",
    "# text_col[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#encoding y_labels truth/fake column to binary values \n",
    "y_labels = []\n",
    "\n",
    "for n in text_df['label']:\n",
    "    if n == 'REAL': \n",
    "        y_labels.append(0)\n",
    "    else: \n",
    "        y_labels.append(1)\n",
    "        \n",
    "text_df['binary'] = y_labels\n",
    "text_df\n",
    "\n",
    "y_labels = y_labels[0:500]\n",
    "\n",
    "print(len(y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#sample data for dev, comment out at the end \n",
    "\n",
    "text_col = text_df['text'][0:500]\n",
    "y_tf_labels = text_df['label'][0:500]\n",
    "print(len(y_tf_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stats(data, n=500):\n",
    "    '''\n",
    "    Print total wordcount and n top terms.\n",
    "    Takes a Counter object and a number of terms to print.\n",
    "    Returns None.\n",
    "    '''\n",
    "    print('Total words in the text:', sum(data.values()))\n",
    "    print('\\nTop X num words by frequency:')\n",
    "    for word in data.most_common(500):\n",
    "        print(word[0], '\\t', word[1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install spaCy\n",
    "# !conda install -c conda-forge spacy spacy-lookups-data -y\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the text: 230435\n",
      "\n",
      "Top X num words by frequency:\n",
      "trump \t 1928\n",
      "said \t 1788\n",
      "clinton \t 1666\n",
      "would \t 1020\n",
      "people \t 935\n",
      "one \t 876\n",
      "obama \t 837\n",
      "new \t 797\n",
      "state \t 766\n",
      "campaign \t 727\n",
      "president \t 696\n",
      "also \t 672\n",
      "us \t 658\n",
      "hillary \t 617\n",
      "could \t 581\n",
      "time \t 559\n",
      "like \t 552\n",
      "states \t 500\n",
      "party \t 492\n",
      "even \t 491\n",
      "republican \t 470\n",
      "many \t 469\n",
      "two \t 461\n",
      "going \t 455\n",
      "first \t 453\n",
      "election \t 440\n",
      "government \t 436\n",
      "donald \t 425\n",
      "country \t 416\n",
      "house \t 413\n",
      "get \t 406\n",
      "make \t 396\n",
      "political \t 395\n",
      "way \t 394\n",
      "american \t 392\n",
      "sanders \t 392\n",
      "last \t 391\n",
      "world \t 390\n",
      "news \t 388\n",
      "u.s. \t 388\n",
      "think \t 385\n",
      "years \t 381\n",
      "much \t 363\n",
      "know \t 354\n",
      "told \t 354\n",
      "democratic \t 344\n",
      "america \t 344\n",
      "say \t 344\n",
      "may \t 342\n",
      "right \t 337\n",
      "voters \t 333\n",
      "republicans \t 323\n",
      "presidential \t 323\n",
      "percent \t 323\n",
      "white \t 321\n",
      "back \t 319\n",
      "vote \t 318\n",
      "made \t 312\n",
      "well \t 311\n",
      "war \t 306\n",
      "support \t 301\n",
      "still \t 299\n",
      "day \t 298\n",
      "see \t 293\n",
      "americans \t 292\n",
      "former \t 292\n",
      "national \t 288\n",
      "year \t 286\n",
      "media \t 284\n",
      "democrats \t 283\n",
      "public \t 283\n",
      "want \t 282\n",
      "take \t 282\n",
      "washington \t 281\n",
      "candidate \t 280\n",
      "united \t 280\n",
      "since \t 278\n",
      "women \t 268\n",
      "law \t 267\n",
      "another \t 266\n",
      "iran \t 265\n",
      "good \t 260\n",
      "isis \t 259\n",
      "department \t 257\n",
      "according \t 247\n",
      "part \t 247\n",
      "fbi \t 245\n",
      "cruz \t 244\n",
      "‘ \t 244\n",
      "go \t 243\n",
      "week \t 243\n",
      "every \t 239\n",
      "bush \t 239\n",
      "policy \t 237\n",
      "police \t 234\n",
      "military \t 233\n",
      "security \t 228\n",
      "congress \t 228\n",
      "need \t 226\n",
      "york \t 225\n",
      "emails \t 225\n",
      "really \t 224\n",
      "says \t 224\n",
      "work \t 224\n",
      "including \t 222\n",
      "help \t 220\n",
      "senate \t 218\n",
      "email \t 216\n",
      "among \t 213\n",
      "gop \t 213\n",
      "group \t 212\n",
      "whether \t 209\n",
      "money \t 208\n",
      "deal \t 206\n",
      "long \t 205\n",
      "around \t 204\n",
      "foreign \t 204\n",
      "use \t 204\n",
      "power \t 203\n",
      "things \t 202\n",
      "million \t 202\n",
      "federal \t 201\n",
      "never \t 201\n",
      "next \t 199\n",
      "court \t 198\n",
      "bill \t 197\n",
      "times \t 196\n",
      "far \t 196\n",
      "put \t 196\n",
      "might \t 195\n",
      "race \t 195\n",
      "russia \t 195\n",
      "saying \t 194\n",
      "religious \t 194\n",
      "called \t 194\n",
      "administration \t 194\n",
      "likely \t 193\n",
      "come \t 190\n",
      "john \t 189\n",
      "candidates \t 188\n",
      "change \t 188\n",
      "end \t 188\n",
      "report \t 188\n",
      "something \t 187\n",
      "look \t 186\n",
      "investigation \t 184\n",
      "become \t 184\n",
      "system \t 184\n",
      "win \t 183\n",
      "better \t 182\n",
      "least \t 182\n",
      "believe \t 181\n",
      "without \t 180\n",
      "debate \t 179\n",
      "officials \t 179\n",
      "life \t 178\n",
      "though \t 178\n",
      "iraq \t 177\n",
      "rights \t 177\n",
      "used \t 175\n",
      "general \t 175\n",
      "recent \t 173\n",
      "real \t 172\n",
      "days \t 171\n",
      "press \t 171\n",
      "tuesday \t 171\n",
      "found \t 171\n",
      "past \t 170\n",
      "information \t 169\n",
      "lot \t 169\n",
      "politics \t 169\n",
      "primary \t 169\n",
      "october \t 168\n",
      "today \t 167\n",
      "secretary \t 167\n",
      "three \t 167\n",
      "case \t 167\n",
      "syria \t 167\n",
      "less \t 166\n",
      "big \t 166\n",
      "act \t 165\n",
      "number \t 165\n",
      "point \t 165\n",
      "nominee \t 164\n",
      "man \t 163\n",
      "issues \t 163\n",
      "office \t 163\n",
      "family \t 162\n",
      "black \t 160\n",
      "fact \t 159\n",
      "let \t 159\n",
      "already \t 158\n",
      "keep \t 158\n",
      "health \t 158\n",
      "economic \t 158\n",
      "conservative \t 157\n",
      "left \t 157\n",
      "sen. \t 157\n",
      "city \t 155\n",
      "care \t 155\n",
      "enough \t 154\n",
      "nation \t 154\n",
      "best \t 154\n",
      "however \t 153\n",
      "issue \t 153\n",
      "little \t 150\n",
      "facebook \t 150\n",
      "supporters \t 150\n",
      "committee \t 150\n",
      "top \t 149\n",
      "across \t 149\n",
      "seen \t 149\n",
      "attack \t 148\n",
      "paul \t 148\n",
      "possible \t 148\n",
      "great \t 147\n",
      "came \t 146\n",
      "yet \t 146\n",
      "important \t 146\n",
      "post \t 145\n",
      "lesley \t 145\n",
      "leaders \t 144\n",
      "stahl \t 144\n",
      "clear \t 143\n",
      "given \t 142\n",
      "forces \t 142\n",
      "several \t 142\n",
      "got \t 141\n",
      "took \t 141\n",
      "show \t 141\n",
      "actually \t 141\n",
      "night \t 141\n",
      "matter \t 140\n",
      "months \t 139\n",
      "later \t 139\n",
      "able \t 139\n",
      "tax \t 139\n",
      "order \t 139\n",
      "voting \t 139\n",
      "business \t 138\n",
      "children \t 138\n",
      "place \t 137\n",
      "early \t 136\n",
      "nuclear \t 136\n",
      "different \t 136\n",
      "give \t 135\n",
      "members \t 135\n",
      "fox \t 135\n",
      "control \t 134\n",
      "asked \t 134\n",
      "rubio \t 134\n",
      "away \t 133\n",
      "home \t 133\n",
      "future \t 133\n",
      "justice \t 133\n",
      "wednesday \t 133\n",
      "job \t 132\n",
      "groups \t 132\n",
      "history \t 131\n",
      "done \t 130\n",
      "making \t 130\n",
      "working \t 130\n",
      "attacks \t 130\n",
      "majority \t 130\n",
      "call \t 129\n",
      "set \t 129\n",
      "ever \t 128\n",
      "november \t 128\n",
      "others \t 127\n",
      "private \t 127\n",
      "'re \t 125\n",
      "parties \t 125\n",
      "freedom \t 124\n",
      "trying \t 124\n",
      "nothing \t 124\n",
      "plan \t 124\n",
      "thursday \t 124\n",
      "friday \t 124\n",
      "social \t 123\n",
      "global \t 123\n",
      "cnn \t 122\n",
      "second \t 122\n",
      "official \t 121\n",
      "must \t 121\n",
      "story \t 121\n",
      "major \t 120\n",
      "running \t 120\n",
      "process \t 120\n",
      "continue \t 119\n",
      "men \t 119\n",
      "run \t 119\n",
      "four \t 119\n",
      "behind \t 118\n",
      "sunday \t 118\n",
      "reported \t 118\n",
      "free \t 118\n",
      "ago \t 117\n",
      "polls \t 117\n",
      "share \t 117\n",
      "wall \t 117\n",
      "comey \t 116\n",
      "poll \t 116\n",
      "find \t 116\n",
      "tell \t 115\n",
      "statement \t 114\n",
      "thing \t 114\n",
      "speech \t 114\n",
      "rules \t 114\n",
      "university \t 114\n",
      "taking \t 113\n",
      "lead \t 113\n",
      "means \t 113\n",
      "known \t 113\n",
      "together \t 113\n",
      "… \t 113\n",
      "course \t 112\n",
      "ryan \t 111\n",
      "instead \t 111\n",
      "within \t 111\n",
      "convention \t 111\n",
      "young \t 111\n",
      "force \t 111\n",
      "intelligence \t 111\n",
      "added \t 111\n",
      "line \t 111\n",
      "leader \t 111\n",
      "killed \t 110\n",
      "role \t 108\n",
      "bernie \t 108\n",
      "delegates \t 108\n",
      "middle \t 108\n",
      "high \t 108\n",
      "nearly \t 108\n",
      "large \t 108\n",
      "trade \t 108\n",
      "senator \t 107\n",
      "question \t 107\n",
      "monday \t 107\n",
      "community \t 107\n",
      "iowa \t 107\n",
      "economy \t 106\n",
      "taken \t 105\n",
      "votes \t 105\n",
      "north \t 105\n",
      "action \t 105\n",
      "talk \t 105\n",
      "woman \t 105\n",
      "problem \t 105\n",
      "results \t 104\n",
      "wants \t 104\n",
      "evidence \t 104\n",
      "interview \t 104\n",
      "israel \t 104\n",
      "sure \t 104\n",
      "month \t 104\n",
      "center \t 103\n",
      "went \t 103\n",
      "close \t 103\n",
      "countries \t 103\n",
      "side \t 103\n",
      "along \t 103\n",
      "data \t 103\n",
      "south \t 103\n",
      "needs \t 102\n",
      "nomination \t 102\n",
      "international \t 102\n",
      "officers \t 102\n",
      "questions \t 101\n",
      "florida \t 101\n",
      "key \t 101\n",
      "death \t 101\n",
      "earlier \t 101\n",
      "based \t 101\n",
      "director \t 100\n",
      "start \t 100\n",
      "seems \t 100\n",
      "anything \t 100\n",
      "video \t 100\n",
      "following \t 100\n",
      "human \t 100\n",
      "person \t 100\n",
      "often \t 99\n",
      "idea \t 99\n",
      "hope \t 99\n",
      "true \t 99\n",
      "texas \t 99\n",
      "comes \t 99\n",
      "russian \t 99\n",
      "almost \t 98\n",
      "street \t 98\n",
      "area \t 98\n",
      "always \t 97\n",
      "agreement \t 97\n",
      "syrian \t 97\n",
      "small \t 97\n",
      "water \t 97\n",
      "foundation \t 96\n",
      "server \t 96\n",
      "air \t 96\n",
      "held \t 96\n",
      "lives \t 96\n",
      "strong \t 96\n",
      "live \t 96\n",
      "pay \t 96\n",
      "mean \t 96\n",
      "either \t 95\n",
      "reason \t 95\n",
      "personal \t 95\n",
      "open \t 95\n",
      "coming \t 95\n",
      "third \t 95\n",
      "policies \t 95\n",
      "wrote \t 95\n",
      "five \t 95\n",
      "supreme \t 95\n",
      "bad \t 94\n",
      "fight \t 93\n",
      "west \t 93\n",
      "islamic \t 93\n",
      "hard \t 92\n",
      "weeks \t 92\n",
      "authorities \t 92\n",
      "current \t 92\n",
      "effort \t 92\n",
      "kind \t 91\n",
      "rather \t 91\n",
      "service \t 91\n",
      "efforts \t 91\n",
      "program \t 91\n",
      "immigration \t 91\n",
      "decision \t 91\n",
      "feel \t 90\n",
      "face \t 90\n",
      "local \t 90\n",
      "barack \t 90\n",
      "source \t 90\n",
      "establishment \t 89\n",
      "chief \t 89\n",
      "using \t 89\n",
      "everyone \t 88\n",
      "leadership \t 88\n",
      "near \t 88\n",
      "march \t 88\n",
      "points \t 88\n",
      "defense \t 88\n",
      "executive \t 88\n",
      "mr. \t 88\n",
      "getting \t 88\n",
      "looking \t 88\n",
      "stand \t 87\n",
      "particularly \t 87\n",
      "team \t 87\n",
      "someone \t 87\n",
      "obamacare \t 87\n",
      "millions \t 87\n",
      "example \t 86\n",
      "laws \t 86\n",
      "despite \t 86\n",
      "gun \t 86\n",
      "china \t 86\n",
      "interest \t 86\n",
      "violence \t 86\n",
      "message \t 86\n",
      "threat \t 85\n",
      "talking \t 85\n",
      "anyone \t 85\n",
      "comments \t 85\n",
      "probably \t 85\n",
      "cases \t 85\n",
      "christie \t 85\n",
      "speaker \t 84\n",
      "enforcement \t 84\n",
      "lost \t 84\n",
      "words \t 84\n",
      "twitter \t 83\n",
      "outside \t 83\n",
      "toward \t 83\n",
      "began \t 83\n",
      "research \t 83\n",
      "event \t 83\n",
      "makes \t 83\n",
      "energy \t 82\n",
      "potential \t 82\n",
      "read \t 82\n",
      "full \t 82\n",
      "leave \t 81\n",
      "western \t 81\n",
      "governor \t 81\n",
      "claim \t 80\n",
      "stop \t 80\n",
      "everything \t 80\n",
      "saturday \t 80\n",
      "released \t 80\n",
      "numbers \t 80\n",
      "base \t 80\n",
      "thought \t 79\n",
      "victory \t 79\n",
      "jobs \t 79\n",
      "strategy \t 79\n",
      "whole \t 79\n"
     ]
    }
   ],
   "source": [
    "# tokenize words (pset 2 tokenization, lemmatization, pset 6 classification)\n",
    "# for loop over text column, \n",
    "\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "custom_stops = [ #do some research on if there's a \"list\" out this\n",
    "    '`',\n",
    "    \"'s\",\n",
    "    \"n't\",\n",
    "    \"’\", \n",
    "    '“', \n",
    "    '”', \n",
    "    '–',\n",
    "    '—', \n",
    "    '000', \n",
    "    '10', \n",
    "    'worth'\n",
    "]\n",
    "\n",
    "for tok in custom_stops:\n",
    "    stops.append(tok)\n",
    "\n",
    "# find punctuation-and/or-digit-only tokens \n",
    "punct_digit = re.compile(f\"^[{string.punctuation}\\d]+$\")\n",
    "\n",
    "text_nltk = Counter()\n",
    "\n",
    "# remove stop words, punctuation, other attributes/ spaces etc \n",
    "\n",
    "for article in text_col:\n",
    "    for token in word_tokenize(article.strip().lower()):\n",
    "        if token not in stops and token.isalpha and token.isnumeric()==False and punct_digit.match(token) is None: #excludes punct\n",
    "            text_nltk[token] +=1\n",
    "\n",
    "word_stats(text_nltk)\n",
    "\n",
    "#tfidif, inverse doc weighting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a preprocessor: tokenize and lemmatize as indicated\n",
    "#need a Doc or Span or Dict(true) obj in place of text_col\n",
    "# from spacy import displacy\n",
    "# displacy.render(text_col, style='dep', options={'distance':100}) # Dependency parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatizer(text):\n",
    "    lemm_tokens = []\n",
    "    \n",
    "    #initialize to empty string \n",
    "    lemm_text_str = '' #space separated words, then use tfidif on this \n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if len(token) >0:\n",
    "            if len(token.lemma_.strip())>0:\n",
    "                if token.pos_ != \"PUNCT\":\n",
    "                    if token.is_stop==False:\n",
    "                        if token.is_alpha==True:\n",
    "#                         lemm_text_str + token.orth_ + ' '\n",
    "                            lemm_tokens.append(token.lemma_)\n",
    "\n",
    "\n",
    "                        #join each token to string with space \n",
    "\n",
    "    #return lemm_text_str\n",
    "    return lemm_tokens\n",
    "\n",
    "# #rewrite function, takes in df col of text, returns \n",
    "# #OR use pandas apply method to the column, will incr apply \n",
    "# #over col with old raw texts, store in new col, single line with apply\n",
    "# #call apply method on text col, pass in lemmtaizer function\n",
    "\n",
    "# #set up vectorizer to take full lemma corpus \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemma_str_list = np.zeros(len(text_df))\n",
    "# print(len(lemma_str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#convert every item in text_col to a str of lemmas, put into lemma str list \n",
    "# lemma_str_list = np.zeros(len(text_df))\n",
    "# print(lemma_str_list)\n",
    "\n",
    "lemma_str_list = []\n",
    "for article_text in text_col:\n",
    "    temp_str = ''\n",
    "    #index_num = text_col.index(article_text)\n",
    "    \n",
    "    temp_lemm = lemmatizer(article_text)\n",
    "    for token in temp_lemm:\n",
    "        temp_str+=token + ' '\n",
    "    lemma_str_list.append(temp_str)\n",
    "print(len(lemma_str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6335-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6335\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while (i<5835):\n",
    "    lemma_str_list.append(0)\n",
    "    i+=1    \n",
    "print(len(lemma_str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Daniel Greenfield Shillman Journalism Fellow F...\n",
       "1    Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
       "2    Secretary State John Kerry say Monday stop Par...\n",
       "3    Kaydee King November lesson tonight dem loss t...\n",
       "4    primary day New York runner Hillary Clinton Do...\n",
       "Name: lemma_str, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put lemma str list into new col of df \n",
    "\n",
    "text_df['lemma_str'] = lemma_str_list\n",
    "text_df['lemma_str'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma Vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #using 2020 dataset \n",
    "# lemm_matrix2020 = count_vectorizer.fit(text_nltk2020)\n",
    "# #lemm_matrix2020.toarray() can't use to array if just fit instead of fit transform \n",
    "# #print(lemm_matrix2020.vocabulary_)\n",
    "# #encode document\n",
    "# vector = count_vectorizer.transform(text_nltk2020)\n",
    "# lemm_matrix2020 = vector.toarray()\n",
    "# lemm_matrix_scaled2020 = scaler.fit(lemm_matrix2020)\n",
    "# lemm_term = pd.DataFrame(lemm_matrix2020, columns=count_vectorizer.get_feature_names())\n",
    "# display(lemm_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete for final submission\n",
    "lemma_str_col = text_df['lemma_str'][0:500]\n",
    "len(lemma_str_col)\n",
    "type(lemma_str_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data vectorizer\n",
    "count_vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             binary = True, \n",
    "                             min_df = 2,\n",
    "                             stop_words='english')\n",
    "\n",
    "lemm_matrix = count_vectorizer.fit_transform(lemma_str_col).toarray()\n",
    "lemm_matrix_scaled = StandardScaler().fit_transform(lemm_matrix)\n",
    "lemm_term = pd.DataFrame(lemm_matrix, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text matrix shape: (500, 9111)\n",
      "text scaled matrix shape: (500, 9111)\n",
      "text term shape: (500, 9111)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbas</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abide</th>\n",
       "      <th>...</th>\n",
       "      <th>zilch</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zor</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerburg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aaron  aback  abandon  abbas  abbott  abc  abduct  abedin  abhor  abide  \\\n",
       "0        0      0        0      0       0    0       0       1      0      0   \n",
       "1        0      0        0      0       0    1       0       0      0      0   \n",
       "2        0      0        0      0       0    0       0       0      0      0   \n",
       "3        0      0        0      0       0    0       0       0      0      0   \n",
       "4        0      0        0      0       0    0       0       0      0      0   \n",
       "..     ...    ...      ...    ...     ...  ...     ...     ...    ...    ...   \n",
       "495      0      0        0      0       0    0       0       0      0      0   \n",
       "496      0      0        0      0       0    1       0       0      0      0   \n",
       "497      0      0        0      0       0    0       0       0      0      0   \n",
       "498      0      0        0      0       0    0       0       0      0      0   \n",
       "499      0      0        0      0       0    1       0       0      0      0   \n",
       "\n",
       "     ...  zilch  zimmerman  zionism  zionist  zip  zone  zones  zor  \\\n",
       "0    ...      0          0        0        0    0     0      0    0   \n",
       "1    ...      0          0        0        0    0     0      0    0   \n",
       "2    ...      0          0        0        0    0     0      0    0   \n",
       "3    ...      0          0        0        0    0     0      0    0   \n",
       "4    ...      0          0        0        0    0     0      0    0   \n",
       "..   ...    ...        ...      ...      ...  ...   ...    ...  ...   \n",
       "495  ...      0          0        0        0    0     0      0    0   \n",
       "496  ...      0          0        0        0    0     0      0    0   \n",
       "497  ...      0          0        0        0    0     0      0    0   \n",
       "498  ...      0          0        0        0    0     0      0    0   \n",
       "499  ...      0          0        0        0    0     0      0    0   \n",
       "\n",
       "     zuckerberg  zuckerburg  \n",
       "0             0           0  \n",
       "1             0           0  \n",
       "2             0           0  \n",
       "3             0           0  \n",
       "4             0           0  \n",
       "..          ...         ...  \n",
       "495           0           0  \n",
       "496           0           0  \n",
       "497           0           0  \n",
       "498           0           0  \n",
       "499           0           0  \n",
       "\n",
       "[500 rows x 9111 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the dimensions of the doc-term matrix\n",
    "print(\"text matrix shape:\", lemm_matrix.shape)\n",
    "print(\"text scaled matrix shape:\", lemm_matrix_scaled.shape)\n",
    "print(\"text term shape:\", lemm_term.shape)\n",
    "\n",
    "#display(text_array)\n",
    "display(lemm_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation and select k best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(lemm_term.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "selector_obj = SelectKBest(mutual_info_classif, k=300)\n",
    "\n",
    "feature300_array= selector_obj.fit_transform(lemm_matrix_scaled, y_labels) #should y be used instead of labels?\n",
    "\n",
    "#display(feature_array)\n",
    "feature300_array.shape\n",
    "\n",
    "#feature300_term = pd.DataFrame(feature300_array, columns= count_vectorizer.get_feature_names())\n",
    "\n",
    "mask = selector_obj.get_support() #list of booleans\n",
    "new_features = [] # The list of your K best features\n",
    "\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        new_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ablaze',\n",
       " 'academia',\n",
       " 'acuman',\n",
       " 'addict',\n",
       " 'adventure',\n",
       " 'advisor',\n",
       " 'alarm',\n",
       " 'anew',\n",
       " 'animal',\n",
       " 'ann',\n",
       " 'anoint',\n",
       " 'antimedia',\n",
       " 'anytime',\n",
       " 'apparent',\n",
       " 'applicant',\n",
       " 'appointment',\n",
       " 'arabia',\n",
       " 'arthur',\n",
       " 'assessment',\n",
       " 'associated',\n",
       " 'atlantic',\n",
       " 'attain',\n",
       " 'attendance',\n",
       " 'attract',\n",
       " 'australia',\n",
       " 'backing',\n",
       " 'bailout',\n",
       " 'barrier',\n",
       " 'bartender',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behold',\n",
       " 'berlin',\n",
       " 'bleak',\n",
       " 'blood',\n",
       " 'bloomberg',\n",
       " 'boehner',\n",
       " 'bogus',\n",
       " 'bold',\n",
       " 'boo',\n",
       " 'boston',\n",
       " 'brush',\n",
       " 'brutal',\n",
       " 'bryant',\n",
       " 'bureaucracy',\n",
       " 'campaign',\n",
       " 'candidacy',\n",
       " 'cap',\n",
       " 'castro',\n",
       " 'catholic',\n",
       " 'caucus',\n",
       " 'certify',\n",
       " 'challenge',\n",
       " 'charleston',\n",
       " 'cheryl',\n",
       " 'cheste',\n",
       " 'chinese',\n",
       " 'citizen',\n",
       " 'clinic',\n",
       " 'closet',\n",
       " 'coalition',\n",
       " 'cohort',\n",
       " 'colossal',\n",
       " 'comfortable',\n",
       " 'confirmation',\n",
       " 'confrontation',\n",
       " 'consistently',\n",
       " 'consumption',\n",
       " 'converge',\n",
       " 'coordination',\n",
       " 'core',\n",
       " 'cosmetic',\n",
       " 'creature',\n",
       " 'crossroad',\n",
       " 'cruz',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'deadly',\n",
       " 'deception',\n",
       " 'decisive',\n",
       " 'declare',\n",
       " 'decline',\n",
       " 'decrease',\n",
       " 'deface',\n",
       " 'demagogue',\n",
       " 'democrats',\n",
       " 'demographic',\n",
       " 'depiction',\n",
       " 'deposition',\n",
       " 'depressed',\n",
       " 'detection',\n",
       " 'detective',\n",
       " 'disgust',\n",
       " 'disney',\n",
       " 'dissenter',\n",
       " 'distraction',\n",
       " 'dividing',\n",
       " 'dmitry',\n",
       " 'domination',\n",
       " 'donor',\n",
       " 'drudge',\n",
       " 'egregious',\n",
       " 'electrical',\n",
       " 'empower',\n",
       " 'endless',\n",
       " 'entire',\n",
       " 'entity',\n",
       " 'entrance',\n",
       " 'essence',\n",
       " 'estranged',\n",
       " 'evoke',\n",
       " 'ex',\n",
       " 'exam',\n",
       " 'excessive',\n",
       " 'export',\n",
       " 'exposure',\n",
       " 'eyebrow',\n",
       " 'facilitate',\n",
       " 'factor',\n",
       " 'faith',\n",
       " 'fear',\n",
       " 'fec',\n",
       " 'fence',\n",
       " 'ferguson',\n",
       " 'feud',\n",
       " 'fifth',\n",
       " 'fighters',\n",
       " 'fishy',\n",
       " 'fluent',\n",
       " 'font',\n",
       " 'footprint',\n",
       " 'fracke',\n",
       " 'friendship',\n",
       " 'frown',\n",
       " 'fundamental',\n",
       " 'garden',\n",
       " 'genius',\n",
       " 'gentleman',\n",
       " 'gop',\n",
       " 'gore',\n",
       " 'grandfather',\n",
       " 'gratitude',\n",
       " 'gutter',\n",
       " 'hacking',\n",
       " 'hal',\n",
       " 'harbor',\n",
       " 'hawkish',\n",
       " 'herman',\n",
       " 'hoarse',\n",
       " 'hollow',\n",
       " 'home',\n",
       " 'horrify',\n",
       " 'hour',\n",
       " 'house',\n",
       " 'hug',\n",
       " 'hunter',\n",
       " 'idaho',\n",
       " 'imprisonment',\n",
       " 'impulse',\n",
       " 'inauthentic',\n",
       " 'inclusion',\n",
       " 'insecure',\n",
       " 'inter',\n",
       " 'intifada',\n",
       " 'iraq',\n",
       " 'isi',\n",
       " 'jihadist',\n",
       " 'june',\n",
       " 'kazakhstan',\n",
       " 'keen',\n",
       " 'kennedy',\n",
       " 'kentucky',\n",
       " 'kiev',\n",
       " 'kirkuk',\n",
       " 'kornacki',\n",
       " 'laboratory',\n",
       " 'lapse',\n",
       " 'lgbt',\n",
       " 'likely',\n",
       " 'low',\n",
       " 'lust',\n",
       " 'macdonald',\n",
       " 'madison',\n",
       " 'marc',\n",
       " 'milkman',\n",
       " 'minded',\n",
       " 'mindless',\n",
       " 'mislead',\n",
       " 'national',\n",
       " 'native',\n",
       " 'neocon',\n",
       " 'new',\n",
       " 'night',\n",
       " 'nomination',\n",
       " 'nonpartisan',\n",
       " 'notification',\n",
       " 'novel',\n",
       " 'nuland',\n",
       " 'oft',\n",
       " 'ohio',\n",
       " 'openly',\n",
       " 'oppression',\n",
       " 'orthodox',\n",
       " 'ouster',\n",
       " 'outset',\n",
       " 'pare',\n",
       " 'party',\n",
       " 'patty',\n",
       " 'payer',\n",
       " 'place',\n",
       " 'politically',\n",
       " 'politician',\n",
       " 'pompeo',\n",
       " 'poorly',\n",
       " 'pot',\n",
       " 'premium',\n",
       " 'president',\n",
       " 'prevent',\n",
       " 'preview',\n",
       " 'primaries',\n",
       " 'primary',\n",
       " 'prosecutor',\n",
       " 'punish',\n",
       " 'quantum',\n",
       " 'quinnipiac',\n",
       " 'quotation',\n",
       " 'race',\n",
       " 'rainbow',\n",
       " 'reach',\n",
       " 'reason',\n",
       " 'refrain',\n",
       " 'republican',\n",
       " 'rio',\n",
       " 'robotic',\n",
       " 'rock',\n",
       " 'roosevelt',\n",
       " 'rupture',\n",
       " 'sanctity',\n",
       " 'satisfy',\n",
       " 'say',\n",
       " 'scholar',\n",
       " 'sear',\n",
       " 'senate',\n",
       " 'shaw',\n",
       " 'showdown',\n",
       " 'shower',\n",
       " 'silently',\n",
       " 'sit',\n",
       " 'smoking',\n",
       " 'solely',\n",
       " 'somewhat',\n",
       " 'soundbite',\n",
       " 'spooky',\n",
       " 'stanford',\n",
       " 'staple',\n",
       " 'station',\n",
       " 'steadfastly',\n",
       " 'stir',\n",
       " 'store',\n",
       " 'subside',\n",
       " 'suffer',\n",
       " 'summary',\n",
       " 'super',\n",
       " 'surrogate',\n",
       " 'tab',\n",
       " 'tablet',\n",
       " 'tad',\n",
       " 'tally',\n",
       " 'tenacity',\n",
       " 'term',\n",
       " 'testing',\n",
       " 'theorist',\n",
       " 'threshold',\n",
       " 'thursday',\n",
       " 'tough',\n",
       " 'translation',\n",
       " 'truth',\n",
       " 'tuesday',\n",
       " 'ubiquitous',\n",
       " 'uk',\n",
       " 'ukraine',\n",
       " 'ultimate',\n",
       " 'ultimately',\n",
       " 'underscore',\n",
       " 'union',\n",
       " 'unpaid',\n",
       " 'unravel',\n",
       " 'unrelated',\n",
       " 'uplifting',\n",
       " 'vengeance',\n",
       " 'vermont',\n",
       " 'void',\n",
       " 'warlord',\n",
       " 'weaponized',\n",
       " 'westerners',\n",
       " 'whopping',\n",
       " 'wife',\n",
       " 'woman',\n",
       " 'worried',\n",
       " 'zor']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from   sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "import spacy\n",
    "import sqlite3\n",
    "from scipy import stats\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06337243, -0.10050378, -0.10050378, ..., -0.52178983,\n",
       "         7.        , -0.06337243],\n",
       "       [-0.06337243, -0.10050378, -0.10050378, ..., -0.52178983,\n",
       "        -0.14285714, -0.06337243],\n",
       "       [-0.06337243, -0.10050378, -0.10050378, ..., -0.52178983,\n",
       "        -0.14285714, -0.06337243],\n",
       "       ...,\n",
       "       [-0.06337243, -0.10050378, -0.10050378, ...,  1.91648042,\n",
       "        -0.14285714, -0.06337243],\n",
       "       [-0.06337243, -0.10050378, -0.10050378, ..., -0.52178983,\n",
       "        -0.14285714, -0.06337243],\n",
       "       [-0.06337243, -0.10050378, -0.10050378, ..., -0.52178983,\n",
       "        -0.14285714, -0.06337243]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test/Train Splits for later use\n",
    "from sklearn.model_selection import train_test_split\n",
    "TEST_SPLIT = 0.2\n",
    "text_term_train, text_term_test, y_train, y_test = train_test_split(feature300_array, y_labels, test_size=TEST_SPLIT)\n",
    "display(text_term_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the performance of our simple classifiers\n",
    "# Freebie function to summarize and display classifier scores\n",
    "def compare_scores(scores_dict):\n",
    "    '''\n",
    "    Takes a dictionary of cross_validate scores.\n",
    "    Returns a color-coded Pandas dataframe that summarizes those scores.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(scores_dict).T.applymap(np.mean).style.background_gradient(cmap='RdYlGn')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Function for Regression Ouput w/ Scatterplot\n",
    "def reg_output(x,y,df):\n",
    "    #x and y are the string column names from base_set of interest\n",
    "    model = LinearRegression().fit(df[[x]],df[y])\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    rsq = model.score(df[[x]],df[y])\n",
    "    r_val = np.sqrt(rsq)\n",
    "    \n",
    "    print('For X = ' + x + ' and Y = ' + y + ' : ')\n",
    "    print(\"Intercept is {intercept:.3f}\".format(intercept = intercept))\n",
    "    print('r-squared is {rsq:.3f}'.format(rsq = rsq))\n",
    "    print('r-value is {r:.3f}'.format(r = r_val))\n",
    "    \n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.scatter(df[x],df[y])\n",
    "    \n",
    "    #best fit code inspired by stackoverflow\n",
    "    z = np.polyfit(df[x],df[y],1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df[x],p(df[x]),\"r--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_conf_it(score_list):\n",
    "    #Find Highest Score:\n",
    "    high_score_list = []\n",
    "    high_keys = score_list.keys()\n",
    "    for key in high_keys:\n",
    "        high_score_list.append(np.mean(score_list[key]['test_accuracy']))\n",
    "    list_max = np.max(high_score_list)\n",
    "    high_key=0\n",
    "    for key in high_keys:\n",
    "    #print(np.mean(SVC_scores[key]['test_accuracy']))\n",
    "        if np.mean(score_list[key]['test_accuracy'])== list_max:\n",
    "            high_key = key\n",
    "    conf_set = score_list[high_key]['test_accuracy']\n",
    "    #print(conf_set)\n",
    "    \n",
    "    n = len(conf_set)\n",
    "    t = stats.t.ppf(q = 0.975, df=n-1) # Get critical value\n",
    "    sigma = np.std(conf_set)       # Calculate sample standard deviation\n",
    "    \n",
    "    margin = t * sigma / np.sqrt(n)\n",
    "    mu = np.mean(conf_set)\n",
    "    low=mu-margin\n",
    "    high=mu+margin\n",
    "    print(\"Key : \" + high_key)\n",
    "    print(\"Max Mean : \" + str(mu))\n",
    "    print(f\"95% confidence interval: ({mu-margin}, {mu+margin})\")\n",
    "    #return(high_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Classifier (SVC)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC, or Support Vector Classifier was selected as an unsupervised learning tool to produce a classifier for the textual data.  First, GridSearchCV was used to identify the best possible combination of parameters to pass through the classifier. The parameter grids used varied the C, kernel, and gamma parameters. C was a regularization parameter to which the strength of the classifier’s regulation is inversely proportional.  Kernel specifies the kernel type that is used in the algorithm. Gamma indicates the Kernel coefficient to be used if the Kernel is “rbf”, “poly” or “sigmoid”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   17.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Best Estimator :  SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "SVC Best Score :  0.78\n",
      "SVC Best Parameters :  {'C': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   18.9s finished\n"
     ]
    }
   ],
   "source": [
    "#SVC GridSearch Varying C, Kernel, Gamma\n",
    "#%%time\n",
    "svc_param_grid = {\n",
    "    'C':[0.001,0.005,0.01,0.25,0.05,0.075,0.1,0.5,0.75],\n",
    "    'kernel':['rbf','linear','poly','sigmoid'],\n",
    "    'gamma':['auto','scale']\n",
    "}\n",
    "svc_grid = GridSearchCV(SVC(),param_grid = svc_param_grid, cv=10,verbose=5,n_jobs=-1)\n",
    "svc_grid.fit(feature300_array,y_labels)\n",
    "print(\"SVC Best Estimator : \" , svc_grid.best_estimator_)\n",
    "print(\"SVC Best Score : \" , svc_grid.best_score_)\n",
    "print(\"SVC Best Parameters : \" , svc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Classifier Dictionary for iteration\n",
    "SVC_dict = {}\n",
    "SVC_dict['defaultSVC'] = SVC()\n",
    "SVC_dict['SVC_1'] = SVC(C=0.001)\n",
    "SVC_dict['SVC_2'] = SVC(C=0.005)\n",
    "SVC_dict['SVC_3'] = SVC(C=0.010)\n",
    "SVC_dict['SVC_4'] = SVC(C=0.025)\n",
    "SVC_dict['SVC_5'] = SVC(C=0.050)\n",
    "SVC_dict['SVC_6'] = SVC(C=0.075)\n",
    "SVC_dict['SVC_7'] = SVC(C=0.100)\n",
    "SVC_dict['SVC_8'] = SVC(C=0.250)\n",
    "SVC_dict['SVC_9'] = SVC(C=0.500)\n",
    "SVC_dict['SVC_10'] = SVC(C=0.750)\n",
    "SVC_dict['SVC_11'] = SVC(C=0.750,gamma='auto')\n",
    "SVC_dict['SVC_12'] = SVC(C=0.750,gamma='scale')\n",
    "SVC_dict['SVC_13'] = SVC(C=0.750,gamma='auto',kernel='rbf')\n",
    "SVC_dict['SVC_14'] = SVC(C=0.750,gamma='auto',kernel='linear')\n",
    "SVC_dict['SVC_15'] = SVC(C=0.750,gamma='auto',kernel='sigmoid')\n",
    "SVC_dict['SVC_16'] = SVC(C=0.750,gamma='auto',kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Score Dictionary for Compare Scores\n",
    "SVC_scores ={}\n",
    "for n in SVC_dict:\n",
    "        SVC_scores[n] = cross_validate( # perform cross-validation\n",
    "        SVC_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_75e68dfa_4237_11eb_b86b_acde48001122row0_col0 {\n",
       "            background-color:  #6ec064;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row0_col1 {\n",
       "            background-color:  #70c164;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row0_col2 {\n",
       "            background-color:  #18954f;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row1_col0 {\n",
       "            background-color:  #60ba62;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row1_col1 {\n",
       "            background-color:  #5db961;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row1_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row2_col0 {\n",
       "            background-color:  #39a758;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row2_col1 {\n",
       "            background-color:  #128a49;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row2_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row3_col0 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row3_col1 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row3_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row4_col0 {\n",
       "            background-color:  #04703b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row4_col1 {\n",
       "            background-color:  #06733d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row4_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row5_col0 {\n",
       "            background-color:  #0a7b41;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row5_col1 {\n",
       "            background-color:  #0c7f43;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row5_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row6_col0 {\n",
       "            background-color:  #0a7b41;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row6_col1 {\n",
       "            background-color:  #0d8044;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row6_col2 {\n",
       "            background-color:  #fa9b58;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row7_col0 {\n",
       "            background-color:  #07753e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row7_col1 {\n",
       "            background-color:  #0d8044;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row7_col2 {\n",
       "            background-color:  #fff6b0;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row8_col0 {\n",
       "            background-color:  #138c4a;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row8_col1 {\n",
       "            background-color:  #33a456;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row8_col2 {\n",
       "            background-color:  #b9e176;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row9_col0 {\n",
       "            background-color:  #39a758;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row9_col1 {\n",
       "            background-color:  #63bc62;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row9_col2 {\n",
       "            background-color:  #51b35e;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row10_col0 {\n",
       "            background-color:  #5ab760;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row10_col1 {\n",
       "            background-color:  #42ac5a;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row10_col2 {\n",
       "            background-color:  #18954f;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row11_col0 {\n",
       "            background-color:  #5db961;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row11_col1 {\n",
       "            background-color:  #5db961;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row11_col2 {\n",
       "            background-color:  #18954f;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row12_col0 {\n",
       "            background-color:  #51b35e;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row12_col1 {\n",
       "            background-color:  #51b35e;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row12_col2 {\n",
       "            background-color:  #18954f;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row13_col0 {\n",
       "            background-color:  #5db961;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row13_col1 {\n",
       "            background-color:  #6bbf64;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row13_col2 {\n",
       "            background-color:  #18954f;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row14_col0 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row14_col1 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row14_col2 {\n",
       "            background-color:  #87cb67;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row15_col0 {\n",
       "            background-color:  #feca79;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row15_col1 {\n",
       "            background-color:  #fffab6;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row15_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row16_col0 {\n",
       "            background-color:  #57b65f;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row16_col1 {\n",
       "            background-color:  #4eb15d;\n",
       "            color:  #000000;\n",
       "        }    #T_75e68dfa_4237_11eb_b86b_acde48001122row16_col2 {\n",
       "            background-color:  #f46d43;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_75e68dfa_4237_11eb_b86b_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >fit_time</th>        <th class=\"col_heading level0 col1\" >score_time</th>        <th class=\"col_heading level0 col2\" >test_accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row0\" class=\"row_heading level0 row0\" >defaultSVC</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row0_col0\" class=\"data row0 col0\" >0.070662</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row0_col1\" class=\"data row0 col1\" >0.007690</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row0_col2\" class=\"data row0 col2\" >0.736000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row1\" class=\"row_heading level0 row1\" >SVC_1</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row1_col0\" class=\"data row1 col0\" >0.071264</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row1_col1\" class=\"data row1 col1\" >0.007826</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row1_col2\" class=\"data row1 col2\" >0.528000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row2\" class=\"row_heading level0 row2\" >SVC_2</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row2_col0\" class=\"data row2 col0\" >0.072924</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row2_col1\" class=\"data row2 col1\" >0.008406</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row2_col2\" class=\"data row2 col2\" >0.528000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row3\" class=\"row_heading level0 row3\" >SVC_3</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row3_col0\" class=\"data row3 col0\" >0.077460</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row3_col1\" class=\"data row3 col1\" >0.008773</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row3_col2\" class=\"data row3 col2\" >0.528000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row4\" class=\"row_heading level0 row4\" >SVC_4</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row4_col0\" class=\"data row4 col0\" >0.076937</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row4_col1\" class=\"data row4 col1\" >0.008640</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row4_col2\" class=\"data row4 col2\" >0.528000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row5\" class=\"row_heading level0 row5\" >SVC_5</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row5_col0\" class=\"data row5 col0\" >0.076107</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row5_col1\" class=\"data row5 col1\" >0.008532</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row5_col2\" class=\"data row5 col2\" >0.528000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row6\" class=\"row_heading level0 row6\" >SVC_6</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row6_col0\" class=\"data row6 col0\" >0.076119</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row6_col1\" class=\"data row6 col1\" >0.008513</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row6_col2\" class=\"data row6 col2\" >0.590000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row7\" class=\"row_heading level0 row7\" >SVC_7</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row7_col0\" class=\"data row7 col0\" >0.076499</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row7_col1\" class=\"data row7 col1\" >0.008518</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row7_col2\" class=\"data row7 col2\" >0.636000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row8\" class=\"row_heading level0 row8\" >SVC_8</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row8_col0\" class=\"data row8 col0\" >0.075080</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row8_col1\" class=\"data row8 col1\" >0.008106</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row8_col2\" class=\"data row8 col2\" >0.680000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row9\" class=\"row_heading level0 row9\" >SVC_9</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row9_col0\" class=\"data row9 col0\" >0.072919</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row9_col1\" class=\"data row9 col1\" >0.007792</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row9_col2\" class=\"data row9 col2\" >0.718000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row10\" class=\"row_heading level0 row10\" >SVC_10</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row10_col0\" class=\"data row10 col0\" >0.071608</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row10_col1\" class=\"data row10 col1\" >0.007998</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row10_col2\" class=\"data row10 col2\" >0.736000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row11\" class=\"row_heading level0 row11\" >SVC_11</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row11_col0\" class=\"data row11 col0\" >0.071441</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row11_col1\" class=\"data row11 col1\" >0.007817</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row11_col2\" class=\"data row11 col2\" >0.736000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row12\" class=\"row_heading level0 row12\" >SVC_12</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row12_col0\" class=\"data row12 col0\" >0.071886</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row12_col1\" class=\"data row12 col1\" >0.007911</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row12_col2\" class=\"data row12 col2\" >0.736000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row13\" class=\"row_heading level0 row13\" >SVC_13</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row13_col0\" class=\"data row13 col0\" >0.071376</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row13_col1\" class=\"data row13 col1\" >0.007733</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row13_col2\" class=\"data row13 col2\" >0.736000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row14\" class=\"row_heading level0 row14\" >SVC_14</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row14_col0\" class=\"data row14 col0\" >0.045609</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row14_col1\" class=\"data row14 col1\" >0.003775</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row14_col2\" class=\"data row14 col2\" >0.700000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row15\" class=\"row_heading level0 row15\" >SVC_15</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row15_col0\" class=\"data row15 col0\" >0.057043</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row15_col1\" class=\"data row15 col1\" >0.006193</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row15_col2\" class=\"data row15 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_75e68dfa_4237_11eb_b86b_acde48001122level0_row16\" class=\"row_heading level0 row16\" >SVC_16</th>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row16_col0\" class=\"data row16 col0\" >0.071650</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row16_col1\" class=\"data row16 col1\" >0.007915</td>\n",
       "                        <td id=\"T_75e68dfa_4237_11eb_b86b_acde48001122row16_col2\" class=\"data row16 col2\" >0.574000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe53f63dbd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare Scores output displaying accuracy scores\n",
    "compare_scores(SVC_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best scoring classifier came out with a score of 0.780, with the best combination of parameters setting C to 0.1, gamma to auto, and kernel to sigmoid. In order to evaluate the performance of different combinations of parameters, a list of SVC classifiers varying the C, Gamma, and Kernel Parameters was looped through, with the accuracy scores being printed, alongside the fit time and the score time for each iteration. The highest score was 0.758, whereas the lowest score came out to 0.528. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : SVC_15\n",
      "Max Mean : 0.7579999999999999\n",
      "95% confidence interval: (0.7312720602731883, 0.7847279397268115)\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval for highest scoring classifier\n",
    "accuracy_conf_it(SVC_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the classifier that produced the highest score was used to produce a 95% confidence interval, the low boundary was roughly 0.731 and the high boundary was roughly 0.785; in other words, we are 95% confident that the model would produce an accuracy score between 0.731 and 0.784. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Classifier Dictionary for observing the influence of variation of C on accuracy score\n",
    "#%%time\n",
    "c_SVC_dict = {}\n",
    "c_SVC_dict['SVC_1'] = SVC(C=0.001)\n",
    "c_SVC_dict['SVC_2'] = SVC(C=0.005)\n",
    "c_SVC_dict['SVC_3'] = SVC(C=0.010)\n",
    "c_SVC_dict['SVC_4'] = SVC(C=0.025)\n",
    "c_SVC_dict['SVC_5'] = SVC(C=0.050)\n",
    "c_SVC_dict['SVC_6'] = SVC(C=0.075)\n",
    "c_SVC_dict['SVC_7'] = SVC(C=0.100)\n",
    "c_SVC_dict['SVC_8'] = SVC(C=0.250)\n",
    "c_SVC_dict['SVC_9'] = SVC(C=0.500)\n",
    "c_SVC_dict['SVC_10'] = SVC(C=0.750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Score Dictionary for Compare Scores to observe the influence of variation of C on accuracy score\n",
    "#%%time\n",
    "c_SVC_scores ={}\n",
    "for n in c_SVC_dict:\n",
    "        c_SVC_scores[n] = cross_validate( # perform cross-validation\n",
    "        c_SVC_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C  accuracy_score\n",
      "0  0.001           0.528\n",
      "1  0.005           0.528\n",
      "2  0.010           0.528\n",
      "3  0.025           0.528\n",
      "4  0.050           0.528\n",
      "5  0.075           0.590\n",
      "6  0.100           0.636\n",
      "7  0.250           0.680\n",
      "8  0.500           0.718\n",
      "9  0.750           0.736\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "accuracy_list = []\n",
    "key_list = list(c_SVC_dict.keys())\n",
    "for key in key_list:\n",
    "    c = c_SVC_dict[key].C\n",
    "    c_list.append(c)    \n",
    "    acc_array = c_SVC_scores[key]['test_accuracy']\n",
    "    mean_acc_array= np.mean(acc_array)\n",
    "    accuracy_list.append(mean_acc_array)\n",
    "c_df = pd.DataFrame({'C':c_list,'accuracy_score':accuracy_list})\n",
    "print(c_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For X = C and Y = accuracy_score : \n",
      "Intercept is 0.546\n",
      "r-squared is 0.817\n",
      "r-value is 0.904\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Scatter plot with regession analysis for observing the influence of variation of C on accuracy score\n",
    "reg_output('C','accuracy_score',c_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the earlier for loop suggested the C parameter could be a significant determinant of the model’s accuracy, another dictionary was produced varying the C parameter between 0.001 and 0.750, but keeping all other variables the same. The model’s C values and accuracy scores were stored in a dataframe, plotted on a scatter plot. Regression analysis revealed an r-squared value of 0.817, indicating that the C value had explained roughly 81.7% of the accuracy score’s variability around its mean, suggesting it is a strong positive predictor of the classifier’s accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Classifier was selected to produce a classifier for the textual data. For the decision tree, GridSearchCV did not work effectively given our data, so to evaluate the performance of different combinations of parameters, a list of decision tree classifiers varying the criterion, splitter, and max_depth parameters was looped through, with the accuracy scores being printed, alongside the fit time and the score time for each iteration. The criterion parameter indicated the function to measure the quality of a split. The splitter parameter indicated the strategy used to choose the split at each node. The max_depth parameter indicated the maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devision Tree Classifier Grid did not work because of values in DataFrame\n",
    "# %%time\n",
    "# dct_param_grid = {\n",
    "#     'criterion':[\"gini\",\"entropy\"],\n",
    "#     'splitter':[\"best\",\"random\"],\n",
    "#     'max_depth':[10,25,50,100,None],\n",
    "#     'min_samples_split':[0,2,5,10],\n",
    "#     'max_features':[10,25,50,100,\"auto\",\"sqrt\",\"log2\",None],\n",
    "#     'class_weight':['balanced',None]\n",
    "# }\n",
    "# dct_grid = GridSearchCV(DecisionTreeClassifier,param_grid = dct_param_grid, cv=10,verbose=5,n_jobs=-1)\n",
    "# dct_grid.fit(feature300_array,y_labels)\n",
    "# print(\"DCT Best Estimator : \" , dct_grid.best_estimator_)\n",
    "# print(\"DCT Best Score : \" , dct_grid.best_score_)\n",
    "# print(\"DCT Best Parameters : \" , dct_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier Dictionary and Score Dictionary for iteration and Compare Scores\n",
    "dct_dict = {}\n",
    "dct_dict['defaultDCT'] = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dct_dict['DCT_1'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\")\n",
    "dct_dict['DCT_2'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"random\")\n",
    "dct_dict['DCT_3'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",max_depth=None)\n",
    "dct_dict['DCT_4'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",max_depth=10)\n",
    "dct_dict['DCT_5'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",max_depth=25)\n",
    "dct_dict['DCT_6'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",max_depth=50)\n",
    "dct_dict['DCT_7'] = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",max_depth=100)\n",
    "\n",
    "dct_scores ={}\n",
    "for n in dct_dict:\n",
    "        dct_scores[n] = cross_validate( # perform cross-validation\n",
    "        dct_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_6bd7ac44_4238_11eb_b86b_acde48001122row0_col0 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row0_col1 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row0_col2 {\n",
       "            background-color:  #fed683;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row1_col0 {\n",
       "            background-color:  #b3df72;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row1_col1 {\n",
       "            background-color:  #feea9b;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row1_col2 {\n",
       "            background-color:  #fee999;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row2_col0 {\n",
       "            background-color:  #fed27f;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row2_col1 {\n",
       "            background-color:  #db382b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row2_col2 {\n",
       "            background-color:  #fed683;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row3_col0 {\n",
       "            background-color:  #d1ec86;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row3_col1 {\n",
       "            background-color:  #c21c27;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row3_col2 {\n",
       "            background-color:  #f16640;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row4_col0 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row4_col1 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row4_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row5_col0 {\n",
       "            background-color:  #e2f397;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row5_col1 {\n",
       "            background-color:  #fa9857;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row5_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row6_col0 {\n",
       "            background-color:  #a5d86a;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row6_col1 {\n",
       "            background-color:  #fed07e;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row6_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row7_col0 {\n",
       "            background-color:  #c1e57b;\n",
       "            color:  #000000;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row7_col1 {\n",
       "            background-color:  #c62027;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_6bd7ac44_4238_11eb_b86b_acde48001122row7_col2 {\n",
       "            background-color:  #fee999;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >fit_time</th>        <th class=\"col_heading level0 col1\" >score_time</th>        <th class=\"col_heading level0 col2\" >test_accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row0\" class=\"row_heading level0 row0\" >defaultDCT</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row0_col0\" class=\"data row0 col0\" >0.008155</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row0_col1\" class=\"data row0 col1\" >0.000472</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row0_col2\" class=\"data row0 col2\" >0.662000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row1\" class=\"row_heading level0 row1\" >DCT_1</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row1_col0\" class=\"data row1 col0\" >0.007024</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row1_col1\" class=\"data row1 col1\" >0.000381</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row1_col2\" class=\"data row1 col2\" >0.664000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row2\" class=\"row_heading level0 row2\" >DCT_2</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row2_col0\" class=\"data row2 col0\" >0.005973</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row2_col1\" class=\"data row2 col1\" >0.000330</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row2_col2\" class=\"data row2 col2\" >0.662000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row3\" class=\"row_heading level0 row3\" >DCT_3</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row3_col0\" class=\"data row3 col0\" >0.006814</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row3_col1\" class=\"data row3 col1\" >0.000321</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row3_col2\" class=\"data row3 col2\" >0.654000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row4\" class=\"row_heading level0 row4\" >DCT_4</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row4_col0\" class=\"data row4 col0\" >0.004680</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row4_col1\" class=\"data row4 col1\" >0.000311</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row4_col2\" class=\"data row4 col2\" >0.688000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row5\" class=\"row_heading level0 row5\" >DCT_5</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row5_col0\" class=\"data row5 col0\" >0.006683</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row5_col1\" class=\"data row5 col1\" >0.000354</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row5_col2\" class=\"data row5 col2\" >0.688000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row6\" class=\"row_heading level0 row6\" >DCT_6</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row6_col0\" class=\"data row6 col0\" >0.007110</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row6_col1\" class=\"data row6 col1\" >0.000371</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row6_col2\" class=\"data row6 col2\" >0.646000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122level0_row7\" class=\"row_heading level0 row7\" >DCT_7</th>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row7_col0\" class=\"data row7 col0\" >0.006929</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row7_col1\" class=\"data row7 col1\" >0.000322</td>\n",
       "                        <td id=\"T_6bd7ac44_4238_11eb_b86b_acde48001122row7_col2\" class=\"data row7 col2\" >0.664000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe540192710>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier output displaying accuracy scores\n",
    "compare_scores(dct_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest score was 0.688 and the low score was 0.646. The best performing model had criterion set to gini, splitter set to best, and max depth set to 25.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : DCT_5\n",
      "Max Mean : 0.688\n",
      "95% confidence interval: (0.6607037201763002, 0.7152962798236997)\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval for highest scoring classifier\n",
    "accuracy_conf_it(dct_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the classifier that produced the highest score was used to produce a 95% confidence interval, the low boundary was roughly 0.661 and the high boundary was roughly 0.715. In other words, we are 95% confident that the model would produce an accuracy score between 0.661 and 0.715."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier Dictionary for observing the influence of variation of max_depth on accuracy score\n",
    "#%%time\n",
    "depth_DCT_dict = {}\n",
    "depth_DCT_dict['DCT_1'] = DecisionTreeClassifier(max_depth=1)\n",
    "depth_DCT_dict['DCT_2'] = DecisionTreeClassifier(max_depth=5)\n",
    "depth_DCT_dict['DCT_3'] = DecisionTreeClassifier(max_depth=10)\n",
    "depth_DCT_dict['DCT_4'] = DecisionTreeClassifier(max_depth=25)\n",
    "depth_DCT_dict['DCT_5'] = DecisionTreeClassifier(max_depth=50)\n",
    "depth_DCT_dict['DCT_6'] = DecisionTreeClassifier(max_depth=75)\n",
    "depth_DCT_dict['DCT_7'] = DecisionTreeClassifier(max_depth=100)\n",
    "depth_DCT_dict['DCT_8'] = DecisionTreeClassifier(max_depth=150)\n",
    "depth_DCT_dict['DCT_9'] = DecisionTreeClassifier(max_depth=200)\n",
    "depth_DCT_dict['DCT_10'] = DecisionTreeClassifier(max_depth=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 639 ms, sys: 5.64 ms, total: 645 ms\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "depth_DCT_scores ={}\n",
    "for n in depth_DCT_dict:\n",
    "        depth_DCT_scores[n] = cross_validate( # perform cross-validation\n",
    "        depth_DCT_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth  accuracy_score\n",
      "0          1           0.676\n",
      "1          5           0.744\n",
      "2         10           0.700\n",
      "3         25           0.702\n",
      "4         50           0.664\n",
      "5         75           0.658\n",
      "6        100           0.664\n",
      "7        150           0.662\n",
      "8        200           0.646\n",
      "9        250           0.664\n"
     ]
    }
   ],
   "source": [
    "depth_list = []\n",
    "accuracy_list = []\n",
    "key_list = list(depth_DCT_dict.keys())\n",
    "for key in key_list:\n",
    "    max_depth = depth_DCT_dict[key].max_depth\n",
    "    depth_list.append(max_depth)  \n",
    "    \n",
    "    acc_array = depth_DCT_scores[key]['test_accuracy']\n",
    "    mean_acc_array= np.mean(acc_array)\n",
    "    accuracy_list.append(mean_acc_array)\n",
    "depth_df = pd.DataFrame({'max_depth':depth_list,'accuracy_score':accuracy_list})\n",
    "print(depth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For X = max_depth and Y = accuracy_score : \n",
      "Intercept is 0.697\n",
      "r-squared is 0.411\n",
      "r-value is 0.641\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Scatter plot with regession analysis for observing the influence of variation of max_depth on accuracy score\n",
    "reg_output('max_depth','accuracy_score',depth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the earlier for loop suggested the max_depth parameter was a significant determinant of the model’s accuracy, another dictionary was produced varying the max_depth parameter between 1 and 250, but keeping all other variables the same. The model’s max_depth values and accuracy scores were stored in a dataframe, plotted on a scatter plot. Regression analysis revealed that an r-squared value of 0.411, indicating that the max_depth value had explained roughly 41.1% of the accuracy score’s variability around its mean, suggesting it is a somewhat strong positive predictor of the classifier’s accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier was selected to produce a classifier for the textual data. For the random forest classifier, GridSearchCV did not work effectively given our data, so to evaluate the performance of different combinations of parameters, a list of random forest classifiers varying the n_estimators, criterion, samples_split, and max_features parameters was looped through, with the accuracy scores being printed, alongside the fit time and the score time for each iteration. The n_estimators parameter indicated the number of trees in the model’s forest. The criterion parameter, similarly as in the decision tree classifier indicated the function to measure the quality of a split. The min_samples_split parameter indicated the minimum number of samples required to split an internal node. The max features parameter indicated the number of features to consider when looking for the best split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, GridSearchCV was not appropriate given the data, and thus it was manually varied below\n",
    "#Random Forest Classifier Dictionary and Score Dictionary for iteration and Compare Scores\n",
    "#%%time\n",
    "rfc_dict = {}\n",
    "rfc_dict['defaultRFC'] = RandomForestClassifier()\n",
    "rfc_dict['RFC_1'] = RandomForestClassifier(n_estimators=20)\n",
    "rfc_dict['RFC_2'] = RandomForestClassifier(n_estimators=50)\n",
    "rfc_dict['RFC_3'] = RandomForestClassifier(n_estimators=100)\n",
    "rfc_dict['RFC_4'] = RandomForestClassifier(n_estimators=150)\n",
    "rfc_dict['RFC_5'] = RandomForestClassifier(n_estimators=200)\n",
    "rfc_dict['RFC_6'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\")\n",
    "rfc_dict['RFC_7'] = RandomForestClassifier(n_estimators=100,criterion=\"entropy\")\n",
    "rfc_dict['RFC_8'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=10)\n",
    "rfc_dict['RFC_9'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=15)\n",
    "rfc_dict['RFC_10'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=20)\n",
    "rfc_dict['RFC_11'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=2)\n",
    "rfc_dict['RFC_12'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=2,max_features=\"auto\")\n",
    "rfc_dict['RFC_13'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=2,max_features=\"log2\")\n",
    "rfc_dict['RFC_14'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=2,max_features=5)\n",
    "rfc_dict['RFC_15'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=2,max_features=\"auto\", bootstrap=True)\n",
    "rfc_dict['RFC_16'] = RandomForestClassifier(n_estimators=100,criterion=\"gini\",min_samples_split=2,max_features=\"auto\", bootstrap=False)\n",
    "\n",
    "#print(rfc_dict)\n",
    "#nans in training - could be a label in the test set that wasn't in train set \n",
    "#unless theres a ssytematic ordering to the list\n",
    "rfc_scores ={}\n",
    "for n in rfc_dict:\n",
    "        rfc_scores[n] = cross_validate( # perform cross-validation\n",
    "        rfc_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "        scoring=['accuracy']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_71dd9666_4239_11eb_b86b_acde48001122row0_col0 {\n",
       "            background-color:  #fee695;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row0_col1 {\n",
       "            background-color:  #fee999;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row0_col2 {\n",
       "            background-color:  #f1f9ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row1_col0 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row1_col1 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row1_col2 {\n",
       "            background-color:  #ca2427;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row2_col0 {\n",
       "            background-color:  #ee613e;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row2_col1 {\n",
       "            background-color:  #f36b42;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row2_col2 {\n",
       "            background-color:  #d1ec86;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row3_col0 {\n",
       "            background-color:  #fedc88;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row3_col1 {\n",
       "            background-color:  #fee08b;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row3_col2 {\n",
       "            background-color:  #f7814c;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row4_col0 {\n",
       "            background-color:  #addc6f;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row4_col1 {\n",
       "            background-color:  #b3df72;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row4_col2 {\n",
       "            background-color:  #e65036;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row5_col0 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row5_col1 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row5_col2 {\n",
       "            background-color:  #fff3ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row6_col0 {\n",
       "            background-color:  #fff5ae;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row6_col1 {\n",
       "            background-color:  #fff7b2;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row6_col2 {\n",
       "            background-color:  #fed884;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row7_col0 {\n",
       "            background-color:  #fff7b2;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row7_col1 {\n",
       "            background-color:  #fff6b0;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row7_col2 {\n",
       "            background-color:  #f1f9ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row8_col0 {\n",
       "            background-color:  #feeb9d;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row8_col1 {\n",
       "            background-color:  #fffdbc;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row8_col2 {\n",
       "            background-color:  #a9da6c;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row9_col0 {\n",
       "            background-color:  #fff0a6;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row9_col1 {\n",
       "            background-color:  #eef8a8;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row9_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row10_col0 {\n",
       "            background-color:  #fecc7b;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row10_col1 {\n",
       "            background-color:  #fee18d;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row10_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row11_col0 {\n",
       "            background-color:  #fee28f;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row11_col1 {\n",
       "            background-color:  #fff5ae;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row11_col2 {\n",
       "            background-color:  #a9da6c;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row12_col0 {\n",
       "            background-color:  #fede89;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row12_col1 {\n",
       "            background-color:  #fee18d;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row12_col2 {\n",
       "            background-color:  #f1f9ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row13_col0 {\n",
       "            background-color:  #fed683;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row13_col1 {\n",
       "            background-color:  #fee28f;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row13_col2 {\n",
       "            background-color:  #fff3ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row14_col0 {\n",
       "            background-color:  #fee695;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row14_col1 {\n",
       "            background-color:  #fdfebc;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row14_col2 {\n",
       "            background-color:  #fed884;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row15_col0 {\n",
       "            background-color:  #fff3ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row15_col1 {\n",
       "            background-color:  #f1f9ac;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row15_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row16_col0 {\n",
       "            background-color:  #fee491;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row16_col1 {\n",
       "            background-color:  #fee999;\n",
       "            color:  #000000;\n",
       "        }    #T_71dd9666_4239_11eb_b86b_acde48001122row16_col2 {\n",
       "            background-color:  #f1f9ac;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_71dd9666_4239_11eb_b86b_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >fit_time</th>        <th class=\"col_heading level0 col1\" >score_time</th>        <th class=\"col_heading level0 col2\" >test_accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row0\" class=\"row_heading level0 row0\" >defaultRFC</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row0_col0\" class=\"data row0 col0\" >0.192586</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row0_col1\" class=\"data row0 col1\" >0.009979</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row0_col2\" class=\"data row0 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row1\" class=\"row_heading level0 row1\" >RFC_1</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row1_col0\" class=\"data row1 col0\" >0.037161</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row1_col1\" class=\"data row1 col1\" >0.002435</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row1_col2\" class=\"data row1 col2\" >0.746000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row2\" class=\"row_heading level0 row2\" >RFC_2</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row2_col0\" class=\"data row2 col0\" >0.104197</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row2_col1\" class=\"data row2 col1\" >0.005892</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row2_col2\" class=\"data row2 col2\" >0.760000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row3\" class=\"row_heading level0 row3\" >RFC_3</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row3_col0\" class=\"data row3 col0\" >0.181566</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row3_col1\" class=\"data row3 col1\" >0.009510</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row3_col2\" class=\"data row3 col2\" >0.750000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row4\" class=\"row_heading level0 row4\" >RFC_4</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row4_col0\" class=\"data row4 col0\" >0.291167</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row4_col1\" class=\"data row4 col1\" >0.014333</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row4_col2\" class=\"data row4 col2\" >0.748000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row5\" class=\"row_heading level0 row5\" >RFC_5</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row5_col0\" class=\"data row5 col0\" >0.406741</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row5_col1\" class=\"data row5 col1\" >0.020106</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row5_col2\" class=\"data row5 col2\" >0.756000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row6\" class=\"row_heading level0 row6\" >RFC_6</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row6_col0\" class=\"data row6 col0\" >0.210312</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row6_col1\" class=\"data row6 col1\" >0.010820</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row6_col2\" class=\"data row6 col2\" >0.754000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row7\" class=\"row_heading level0 row7\" >RFC_7</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row7_col0\" class=\"data row7 col0\" >0.213075</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row7_col1\" class=\"data row7 col1\" >0.010775</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row7_col2\" class=\"data row7 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row8\" class=\"row_heading level0 row8\" >RFC_8</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row8_col0\" class=\"data row8 col0\" >0.198845</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row8_col1\" class=\"data row8 col1\" >0.011188</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row8_col2\" class=\"data row8 col2\" >0.762000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row9\" class=\"row_heading level0 row9\" >RFC_9</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row9_col0\" class=\"data row9 col0\" >0.203945</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row9_col1\" class=\"data row9 col1\" >0.012098</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row9_col2\" class=\"data row9 col2\" >0.770000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row10\" class=\"row_heading level0 row10\" >RFC_10</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row10_col0\" class=\"data row10 col0\" >0.171088</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row10_col1\" class=\"data row10 col1\" >0.009547</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row10_col2\" class=\"data row10 col2\" >0.770000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row11\" class=\"row_heading level0 row11\" >RFC_11</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row11_col0\" class=\"data row11 col0\" >0.188196</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row11_col1\" class=\"data row11 col1\" >0.010656</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row11_col2\" class=\"data row11 col2\" >0.762000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row12\" class=\"row_heading level0 row12\" >RFC_12</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row12_col0\" class=\"data row12 col0\" >0.183762</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row12_col1\" class=\"data row12 col1\" >0.009552</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row12_col2\" class=\"data row12 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row13\" class=\"row_heading level0 row13\" >RFC_13</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row13_col0\" class=\"data row13 col0\" >0.177340</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row13_col1\" class=\"data row13 col1\" >0.009669</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row13_col2\" class=\"data row13 col2\" >0.756000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row14\" class=\"row_heading level0 row14\" >RFC_14</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row14_col0\" class=\"data row14 col0\" >0.192553</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row14_col1\" class=\"data row14 col1\" >0.011352</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row14_col2\" class=\"data row14 col2\" >0.754000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row15\" class=\"row_heading level0 row15\" >RFC_15</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row15_col0\" class=\"data row15 col0\" >0.208788</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row15_col1\" class=\"data row15 col1\" >0.011925</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row15_col2\" class=\"data row15 col2\" >0.744000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_71dd9666_4239_11eb_b86b_acde48001122level0_row16\" class=\"row_heading level0 row16\" >RFC_16</th>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row16_col0\" class=\"data row16 col0\" >0.189950</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row16_col1\" class=\"data row16 col1\" >0.009965</td>\n",
       "                        <td id=\"T_71dd9666_4239_11eb_b86b_acde48001122row16_col2\" class=\"data row16 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe54014b590>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare Scores output displaying accuracy scores\n",
    "compare_scores(rfc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest score was 0.770 and the lowest score was 0.744. The highest performing model had n_estimators set to 100, criterion set to gini, min_samples_split set to 15, and max_features set to the default of auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : RFC_9\n",
      "Max Mean : 0.7700000000000001\n",
      "95% confidence interval: (0.7365996497576898, 0.8034003502423105)\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval for highest scoring classifier\n",
    "accuracy_conf_it(rfc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the classifier that produced the highest score was used to produce a 95% confidence interval, the low boundary was roughly 0.737 and the high boundary was 0.803. In other words, we are 95% confident that the model would produce an accuracy score between 0.737 and 0.803."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier Dictionary for observing the influence of variation of n_estimators on accuracy score\n",
    "#%%time\n",
    "est_rfc_dict = {}\n",
    "est_rfc_dict['RFC_1'] = RandomForestClassifier(n_estimators=10)\n",
    "est_rfc_dict['RFC_2'] = RandomForestClassifier(n_estimators=20)\n",
    "est_rfc_dict['RFC_3'] = RandomForestClassifier(n_estimators=50)\n",
    "est_rfc_dict['RFC_4'] = RandomForestClassifier(n_estimators=100)\n",
    "est_rfc_dict['RFC_5'] = RandomForestClassifier(n_estimators=150)\n",
    "est_rfc_dict['RFC_6'] = RandomForestClassifier(n_estimators=200)\n",
    "est_rfc_dict['RFC_7'] = RandomForestClassifier(n_estimators=250)\n",
    "est_rfc_dict['RFC_8'] = RandomForestClassifier(n_estimators=300)\n",
    "est_rfc_dict['RFC_9'] = RandomForestClassifier(n_estimators=350)\n",
    "est_rfc_dict['RFC_10'] = RandomForestClassifier(n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forst Score Dictionary for Compare Scores to observe the influence of variation of n_estimators on accuracy score\n",
    "#%%time\n",
    "est_rfc_scores ={}\n",
    "for n in est_rfc_dict:\n",
    "        est_rfc_scores[n] = cross_validate( # perform cross-validation\n",
    "        est_rfc_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_estimators  accuracy_score\n",
      "0            10           0.738\n",
      "1            20           0.762\n",
      "2            50           0.762\n",
      "3           100           0.762\n",
      "4           150           0.764\n",
      "5           200           0.756\n",
      "6           250           0.756\n",
      "7           300           0.762\n",
      "8           350           0.760\n",
      "9           400           0.756\n"
     ]
    }
   ],
   "source": [
    "est_list = []\n",
    "accuracy_list = []\n",
    "key_list = list(est_rfc_dict.keys())\n",
    "for key in key_list:\n",
    "    est = est_rfc_dict[key].n_estimators\n",
    "    est_list.append(est)    \n",
    "    acc_array = est_rfc_scores[key]['test_accuracy']\n",
    "    mean_acc_array= np.mean(acc_array)\n",
    "    accuracy_list.append(mean_acc_array)\n",
    "est_df = pd.DataFrame({'n_estimators':est_list,'accuracy_score':accuracy_list})\n",
    "print(est_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For X = n_estimators and Y = accuracy_score : \n",
      "Intercept is 0.756\n",
      "r-squared is 0.042\n",
      "r-value is 0.205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Scatter plot with regession analysis for observing the influence of variation of  on accuracy score\n",
    "reg_output('n_estimators','accuracy_score',est_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the earlier for loop suggested the n_estimarors parameter was a significant determinant of the model’s accuracy, another dictionary was produced varying the n_estimators parameter between 10 and 400, but keeping all other variables the same. The model’s n_estimators values and accuracy scores were stored in a dataframe, plotted on a scatter plot. Regression analysis revealed that the model's r-squared value was 0.205, indicating that the n_estimators value had explained roughly 20.5% of the accuracy score’s variability around its mean, suggesting it is a weak-to-moderate predictor of the classifier’s accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-layer Perceptron classifier (MLP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP, or Multi-layer Perceptron classifier was selected to produce a classifier for the textual data; unlike many other classifiers, the MLP classifier relies on an underlying Neural Network for classification. The GridSearchCV Model was initially used to obtain the best possible combination of parameters to pass through the classifier. The variables alpha, hidden_layer_sizes, and max_iter were varied. Alpha indicated the L2 penalty regularization term parameter. For hidden_layer_sizes the nth element represents the number of neurons in the nth hidden layer. The max_iter parameter indicates the maximum number of iterations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch was Previously used but was extremely time consuming. Ouput was as follows:\n",
    "# MLP Best Score :  0.8160000000000001\n",
    "# MLP Best Parameters :  {'alpha': 2, 'hidden_layer_sizes': 25, 'max_iter': 100}\n",
    "# %%time\n",
    "# mlp_param_grid = {\n",
    "#     'hidden_layer_sizes': [0,1,5,10,25,50,100,200],\n",
    "#     'alpha':[0.001,0.005,0.01,0.25,0.05,0.075,0.1,0.5,0.75,1,2,5,10],\n",
    "#     'max_iter':[100,200,500,1000,None]\n",
    "# }\n",
    "# mlp_grid = GridSearchCV(MLPClassifier(),param_grid = mlp_param_grid, cv=10,verbose=5,n_jobs=-1)\n",
    "# mlp_grid.fit(feature300_array,y_labels)\n",
    "# print(\"MLP Best Estimator : \" , mlp_grid.best_estimator_)\n",
    "# print(\"MLP Best Score : \" , mlp_grid.best_score_)\n",
    "# print(\"MLP Best Parameters : \" , mlp_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process (commented out above) took an extensive amount of time to run, but revealed a high score of 0.770, with the best combination of parameters setting alpha to 2, hidden_layer_sizes to 25, and max_iter to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier Dictionary for iteration (Certain iterations were commented out based on relevancy)\n",
    "#%%time\n",
    "mlp_dict = {}\n",
    "mlp_dict['defaultMLP'] = MLPClassifier()\n",
    "mlp_dict['MLP_1'] = MLPClassifier(alpha=0.01)\n",
    "# mlp_dict['MLP_2'] = MLPClassifier(alpha=0.05)\n",
    "# mlp_dict['MLP_3'] = MLPClassifier(alpha=0.1)\n",
    "mlp_dict['MLP_4'] = MLPClassifier(alpha=0.5)\n",
    "mlp_dict['MLP_5'] = MLPClassifier(alpha=1.0)\n",
    "# mlp_dict['MLP_6'] = MLPClassifier(alpha=1.5)\n",
    "mlp_dict['MLP_7'] = MLPClassifier(alpha=2.0)\n",
    "mlp_dict['MLP_7'] = MLPClassifier(alpha=3.0)\n",
    "mlp_dict['MLP_8'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 10)\n",
    "mlp_dict['MLP_9'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 25)\n",
    "mlp_dict['MLP_10'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 50)\n",
    "# mlp_dict['MLP_10'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 100)\n",
    "# mlp_dict['MLP_11'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 150)\n",
    "mlp_dict['MLP_12'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 25,max_iter=50)\n",
    "mlp_dict['MLP_13'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 25,max_iter=100)\n",
    "mlp_dict['MLP_14'] = MLPClassifier(alpha=2.0,hidden_layer_sizes = 25,max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#MLP Score Dictionary for Compare Scores\n",
    "#%%time\n",
    "mlp_scores ={}\n",
    "for n in mlp_dict:\n",
    "        mlp_scores[n] = cross_validate( # perform cross-validation\n",
    "        mlp_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a03e6912_423a_11eb_b86b_acde48001122row0_col0 {\n",
       "            background-color:  #63bc62;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row0_col1 {\n",
       "            background-color:  #b9e176;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row0_col2 {\n",
       "            background-color:  #f26841;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row1_col0 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row1_col1 {\n",
       "            background-color:  #a2d76a;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row1_col2 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row2_col0 {\n",
       "            background-color:  #15904c;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row2_col1 {\n",
       "            background-color:  #f7fcb4;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row2_col2 {\n",
       "            background-color:  #b1de71;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row3_col0 {\n",
       "            background-color:  #118848;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row3_col1 {\n",
       "            background-color:  #d5ed88;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row3_col2 {\n",
       "            background-color:  #60ba62;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row4_col0 {\n",
       "            background-color:  #07753e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row4_col1 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row4_col2 {\n",
       "            background-color:  #30a356;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row5_col0 {\n",
       "            background-color:  #f67f4b;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row5_col1 {\n",
       "            background-color:  #e0f295;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row5_col2 {\n",
       "            background-color:  #30a356;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row6_col0 {\n",
       "            background-color:  #fdb567;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row6_col1 {\n",
       "            background-color:  #fedc88;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row6_col2 {\n",
       "            background-color:  #48ae5c;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row7_col0 {\n",
       "            background-color:  #fffdbc;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row7_col1 {\n",
       "            background-color:  #c3e67d;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row7_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row8_col0 {\n",
       "            background-color:  #a50026;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row8_col1 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row8_col2 {\n",
       "            background-color:  #d3ec87;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row9_col0 {\n",
       "            background-color:  #c62027;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row9_col1 {\n",
       "            background-color:  #fecc7b;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row9_col2 {\n",
       "            background-color:  #60ba62;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row10_col0 {\n",
       "            background-color:  #fecc7b;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row10_col1 {\n",
       "            background-color:  #fff5ae;\n",
       "            color:  #000000;\n",
       "        }    #T_a03e6912_423a_11eb_b86b_acde48001122row10_col2 {\n",
       "            background-color:  #006837;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_a03e6912_423a_11eb_b86b_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >fit_time</th>        <th class=\"col_heading level0 col1\" >score_time</th>        <th class=\"col_heading level0 col2\" >test_accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row0\" class=\"row_heading level0 row0\" >defaultMLP</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row0_col0\" class=\"data row0 col0\" >1.008730</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row0_col1\" class=\"data row0 col1\" >0.001128</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row0_col2\" class=\"data row0 col2\" >0.720000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row1\" class=\"row_heading level0 row1\" >MLP_1</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row1_col0\" class=\"data row1 col0\" >1.194848</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row1_col1\" class=\"data row1 col1\" >0.001143</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row1_col2\" class=\"data row1 col2\" >0.708000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row2\" class=\"row_heading level0 row2\" >MLP_4</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row2_col0\" class=\"data row2 col0\" >1.113851</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row2_col1\" class=\"data row2 col1\" >0.001081</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row2_col2\" class=\"data row2 col2\" >0.750000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row3\" class=\"row_heading level0 row3\" >MLP_5</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row3_col0\" class=\"data row3 col0\" >1.130596</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row3_col1\" class=\"data row3 col1\" >0.001110</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row3_col2\" class=\"data row3 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row4\" class=\"row_heading level0 row4\" >MLP_7</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row4_col0\" class=\"data row4 col0\" >1.165864</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row4_col1\" class=\"data row4 col1\" >0.000910</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row4_col2\" class=\"data row4 col2\" >0.762000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row5\" class=\"row_heading level0 row5\" >MLP_8</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row5_col0\" class=\"data row5 col0\" >0.462168</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row5_col1\" class=\"data row5 col1\" >0.001101</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row5_col2\" class=\"data row5 col2\" >0.762000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row6\" class=\"row_heading level0 row6\" >MLP_9</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row6_col0\" class=\"data row6 col0\" >0.542734</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row6_col1\" class=\"data row6 col1\" >0.001039</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row6_col2\" class=\"data row6 col2\" >0.760000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row7\" class=\"row_heading level0 row7\" >MLP_10</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row7_col0\" class=\"data row7 col0\" >0.711782</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row7_col1\" class=\"data row7 col1\" >0.001121</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row7_col2\" class=\"data row7 col2\" >0.770000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row8\" class=\"row_heading level0 row8\" >MLP_12</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row8_col0\" class=\"data row8 col0\" >0.243337</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row8_col1\" class=\"data row8 col1\" >0.001240</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row8_col2\" class=\"data row8 col2\" >0.746000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row9\" class=\"row_heading level0 row9\" >MLP_13</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row9_col0\" class=\"data row9 col0\" >0.308574</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row9_col1\" class=\"data row9 col1\" >0.001029</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row9_col2\" class=\"data row9 col2\" >0.758000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a03e6912_423a_11eb_b86b_acde48001122level0_row10\" class=\"row_heading level0 row10\" >MLP_14</th>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row10_col0\" class=\"data row10 col0\" >0.588231</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row10_col1\" class=\"data row10 col1\" >0.001064</td>\n",
       "                        <td id=\"T_a03e6912_423a_11eb_b86b_acde48001122row10_col2\" class=\"data row10 col2\" >0.770000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe53f5ec890>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare Scores output displaying accuracy scores\n",
    "compare_scores(mlp_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of different combinations of parameters, a list of MLP classifiers varying the alpha, hidden_layer_sizes, and max_iter parameters was looped through, with the accuracy scores being printed, alongside the fit time and the score time for each iteration. This time, the best model had the parameter alpha set to 2, hidden_layer_sizes set to 50, and max_iter set to the default of 200. The highest score was 0.770 and the lowest score was 0.708.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : MLP_14\n",
      "Max Mean : 0.77\n",
      "95% confidence interval: (0.7224408691964241, 0.8175591308035759)\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval for highest scoring classifier\n",
    "accuracy_conf_it(mlp_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the classifier that produced the highest score was used to produce a 95% confidence interval, the low boundary was roughly 0.722 and the high boundary was 0.818. In other words, we are 95% confident that the model would produce an accuracy score between 0.722 and 0.818."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier Dictionary for observing the influence of variation of alpha on accuracy score\n",
    "#%%time\n",
    "alpha_mlp_dict = {}\n",
    "alpha_mlp_dict['defaultMLP'] = MLPClassifier()\n",
    "alpha_mlp_dict['MLP_1'] = MLPClassifier(alpha=0.01)\n",
    "alpha_mlp_dict['MLP_2'] = MLPClassifier(alpha=0.05)\n",
    "alpha_mlp_dict['MLP_3'] = MLPClassifier(alpha=0.075)\n",
    "alpha_mlp_dict['MLP_4'] = MLPClassifier(alpha=0.10)\n",
    "alpha_mlp_dict['MLP_5'] = MLPClassifier(alpha=0.25)\n",
    "alpha_mlp_dict['MLP_6'] = MLPClassifier(alpha=0.50)\n",
    "alpha_mlp_dict['MLP_7'] = MLPClassifier(alpha=0.75)\n",
    "alpha_mlp_dict['MLP_8'] = MLPClassifier(alpha=1.00)\n",
    "alpha_mlp_dict['MLP_9'] = MLPClassifier(alpha=1.25)\n",
    "alpha_mlp_dict['MLP_10'] = MLPClassifier(alpha=1.50)\n",
    "alpha_mlp_dict['MLP_11'] = MLPClassifier(alpha=1.75)\n",
    "alpha_mlp_dict['MLP_12'] = MLPClassifier(alpha=2.00)\n",
    "alpha_mlp_dict['MLP_13'] = MLPClassifier(alpha=2.25)\n",
    "alpha_mlp_dict['MLP_14'] = MLPClassifier(alpha=2.50)\n",
    "alpha_mlp_dict['MLP_15'] = MLPClassifier(alpha=2.75)\n",
    "alpha_mlp_dict['MLP_16'] = MLPClassifier(alpha=3.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#MLP Score Dictionary for Compare Scores to observe the influence of variation of alpha on accuracy score\n",
    "#%%time\n",
    "alpha_mlp_scores ={}\n",
    "for n in alpha_mlp_dict:\n",
    "        alpha_mlp_scores[n] = cross_validate( # perform cross-validation\n",
    "        alpha_mlp_dict[n], # classifier object\n",
    "        feature300_array, # feature matrix\n",
    "        y_labels, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring = ['accuracy']\n",
    "        #scoring=['accuracy', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     alpha  accuracy_score\n",
      "0   0.0001           0.740\n",
      "1   0.0100           0.732\n",
      "2   0.0500           0.736\n",
      "3   0.0750           0.724\n",
      "4   0.1000           0.740\n",
      "5   0.2500           0.740\n",
      "6   0.5000           0.748\n",
      "7   0.7500           0.758\n",
      "8   1.0000           0.764\n",
      "9   1.2500           0.764\n",
      "10  1.5000           0.766\n",
      "11  1.7500           0.768\n",
      "12  2.0000           0.774\n",
      "13  2.2500           0.766\n",
      "14  2.5000           0.764\n",
      "15  2.7500           0.756\n",
      "16  3.0000           0.770\n"
     ]
    }
   ],
   "source": [
    "alpha_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "key_list = list(alpha_mlp_dict.keys())\n",
    "for key in key_list:\n",
    "    alpha = alpha_mlp_dict[key].alpha\n",
    "    alpha_list.append(alpha)\n",
    "    \n",
    "    acc_array = alpha_mlp_scores[key]['test_accuracy'] \n",
    "    mean_acc_array= np.mean(acc_array)\n",
    "    accuracy_list.append(mean_acc_array)\n",
    "aa_df = pd.DataFrame({'alpha':alpha_list,'accuracy_score':accuracy_list})\n",
    "print(aa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For X = alpha and Y = accuracy_score : \n",
      "Intercept is 0.740\n",
      "r-squared is 0.666\n",
      "r-value is 0.816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Scatter plot with regession analysis for observing the influence of variation of alpha on accuracy score\n",
    "reg_output('alpha','accuracy_score',aa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the earlier for loop suggested the alpha parameter was a significant determinant of the model’s accuracy, another dictionary was produced varying the alpha parameter between 0.010 and 3.000, but keeping all other variables the same. The model’s alpha values and accuracy scores were stored in a dataframe, plotted on a scatter plot. Regression analysis revealed an r-squared value of 0.666, indicating that the alpha value had explained roughly 66.6% of the accuracy score’s variability around its mean, suggesting it is a moderately strong positive predictor of the classifier’s accuracy score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that worked the best was the MLP Classifier, producing a high score of .770 and a confidence interval ranging between roughly 0.722 and 0.818. The output, especially the linear regression suggested that the alpha parameter was relatively influential on the accuracy of, bearing an R-Squared value of 0.666.  This was surprising as we had previously anticipated that the best model would be the decision tree mode as it had a tendency to overfit. This investigation was limited by the number of parameters we were able to pass through each model, as well as the range of models we were able to evaluate. Given more time, we would be able to let each model have more processing time and run more parameters through to obtain the most optimal possible results. In the future, it would be rewarding to compare classifier performance on 2016 election data thoroughly with similar data for future elections. \n",
    "\n",
    "From our data exploration stage (more information in appendix) we found that Trump is definitely a high frequency token word and was included in our features used for the final model. Other high frequency tokens include political officials including Hillary Clinton, Barack Obama, and John Mccain, and countries such as Iran and Russia. Finally, we initially intended to also evaluate our classifier on 2020 election related news articles, in order to see if the performance of the model holds at a fairly accurate rate.  This project scope and the issue of fake news itself is definitely one that was really important to us and we were extremely interested in diving into this classification project. However, we wanted to tackle 2020 data sets as well and unfortunately there just wasn’t any large enough datasets that we could find comparable to 2016 given 2020’s recency. Thus, while we finished pre-processing the data for multiple smaller datasets (also included in Appendix) we ultimately did not include this in our project due to time constraints and would like to pursue this in future work! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
